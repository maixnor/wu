---
title: "BA1 Unit 3 - Group 1"
output:
  pdf_document: 
    latex_engine: tectonic
    fig_caption: yes
  html_document: default
date: "2024-11-25"
---

Benjamin Meixner, Maryna Manzharova, Elias Clemens Maria Prackwieser, Richard Takacs

# Setup


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
setwd("~/repo/wu/r/ba1/data")
site_data <- read.csv("site_data.csv", sep = ";",header=TRUE, fill=TRUE)

library(dplyr)
library(ggplot2)
library(psych)
```

# Task 1

First we take a quick look at our dataset to get familiar with the data. The following commands help us get some quick information:

```{r}
head(site_data)

describe(site_data)

str(site_data)
```

We are looking at 1215 observations of 14 variables that represent
online ad results (=marketing data) from 12 websites on 122 days.

Let's go to the first task! Here we will look at the correlation between impressions and the number of ads per page, later on we will check the relation between clicks and impressions.

# Impressions vs. number of ads per page

## a) Scatterplot: how strong is the correlation between Impressions and the number of ads?
```{r}
plot(site_data$number_ads,site_data$impressions)
```
Since the number of impressions are very large and vary widely, it might come handy to also look at a scatterplot that considers a logarithmic transformation of the number of impressions. The log transformation reduces the impact of large values with extremely high outliers (data is highly skewed). Using log we will obtain a relationship that is easier to visualize.
```{r}
log_impressions <- log(site_data$impressions)

plot(site_data$number_ads,log_impressions)

```
Before we comment on our scatterplot, let's calculate also the correlation coefficients for our pair of variables. Here we will look at our original impression values. We can either simply ask R to give us the correlation coefficient using the *cor()* function. Alternatively, we can use the *cor.test()* function that automatically calculates both the correlation coefficient and its p-value.

# b) Correlation coefficient
```{r}
correlation<-cor(site_data$number_ads,site_data$impressions)
print(correlation)

cor.test(site_data$number_ads, site_data$impressions)

```
Our correlation coefficient is 0.6975701. This indicates *moderate-strong positive correlation* between the number of ads per page and the impressions. Also, the p-value is smaller than 0.05. Hence we assume that our relationship is statistically significant.

## c) Comments
As already mentioned before we assume a moderate-strong positive correlation when inspecting the correlation coefficient. If we would only look at our non-logarithmic scatterplot, we could not assume any linear relationship or correlation. Using the logarithm, the correlation indicated by our correlation coefficient becomes more understandable. From looking at the scatterplots we must say that the data is highly skewed: Impressions remain significantly low and increase drastically only when the number of ads per page reaches 14. Therefore, even though the correlation coefficient is moderate-high and positive, this does not mean that we can assume a strong, positive linear relationship.



# Relation between clicks and impressions

## a) Scatterplot

```{r}
plot(site_data$clicks, site_data$impressions)
log_impressions<-log(site_data$impressions)
plot(site_data$clicks,log_impressions)
```
Again we use also the logarithmic number of impressions and compare it to the amount of clicks. This allows for a better visualization.

## b) Correlation coefficient

```{r}
cor.test(site_data$impressions, site_data$clicks)
```
Our p-value is smaller 0.05 which means our result is statistically significant. Correlation = 0.6717794. The correlation between impressions and clicks is a bit lower than the correlation impressions-number of ads. Nonetheless, 0.6717794 indicates a *moderate-high positive correlation between impressions and clicks*.

## c) Comments
From analyzing the non-logarithmic scatterplot one cannot assume a high correlation since the data seemes to be drastically left-skewed. The scatterplot with logarithmic values for "impressions" also indicates a distortion of our data. One should therefore be careful when estimating the significance of the correlation coefficient. There is an association between the variables, but the relationship is not linear.

# Task 2

### Simple Regression I
Let's run a simple regression model for impressions (dependent variable) and number of ads (independent variable)
```{r}
mod0 = lm(impressions ~ number_ads, data = site_data); e <- summary(mod0)
e

```
```{r} 
site_data %>% ggplot(aes(x= number_ads, y= impressions)) +
geom_point()+
geom_smooth(method = "lm")
```

Let's interpret the results.
```{r}
e$coefficients
```
The estimate of intercept is a negative number, it suggests that if there were zero ads, the predicted number of impressions would be negative. In practice, this doesn't make sense, as impressions cannot be negative.This suggests that the model is only valid in ranges where number_ads matches the data input's constrained range.
Coefficient for number of ads is 474641. It means that with one additional ad slot impressions increase by 474641. 
The p-values for intercept and number_ads are smaller than 0.05. It means that we can reject the null hypothesis that intercept and number_ads coefficient are zero â€” intercept and number_adds are statistically significant within the model.
``` {r}
e$r.squared
```
R-squared of 0.4866041 suggests that 48.66% of the variability in impressions is explained by the number of ads. It is not much, therefore perhaps adding additional variables can improve the model.

```{r}
e$adj.r.squared
```
R-squared adjusted is very close to R-squared value. It suggests that the model is not very affected by the number of predictors.

P-value of F-statistic is < 2.2e-16 which is less than 0.05. It means we can reject the null hypothesis that R-squared equals 0 (or all coefficients except for intercept = 0). It suggests that model as a whole is significant. 

### Simple Regression II
Let's run a simple regression model for clicks (dependent variable) and impressions(independent variable)
```{r}
mod1 = lm(clicks ~ impressions, data = site_data); d <- summary(mod1)
d 
```

```{r}
site_data %>% ggplot(aes(x= impressions, y= clicks)) +
geom_point()+
geom_smooth(method = "lm")
```
Let's interpret the results.
``` {r} 
d$coefficients
```
Estimate of intercept suggests that without impressions there are 1.684 clicks. 
Estimate of impressions suggests that additional impression increases number of clicks by 2.097217e-05. 
The p-value for intercept is  bigger than 0.05 - not statistically significant. It means that we cannot reject the null hypothesis that intercept is zero. The p-value for impressions is less than 0.05. We can reject null hypothesis that impressions coefficient is zero. This means impressions coefficient is significant within our model.
```{r}
d$r.squared
```
R-squared of 0.4512875 suggests that 45.12875% of the variability in clicks is explained by impressions. It is not much, therefore adding additional variables can improve the model.
```{r}
d$adj.r.squared
```
R-squared adjusted is very close to R-squared value. It suggests that the model is not very affected by the number of predictors.
p-value of F-statistic is < 2.2e-16 which is less than 0.05. It means we can reject the null hypothesis that R-squared equals 0 (or all coefficients except for intercept = 0). It suggests that model as a whole is significant 

### Predict 5 ad slots

Let's predict number of impressions when a website owner would publish 5 ad slots on their website
```{r}
predicted_imp <- predict(mod0, newdata = list(number_ads = 5))
cat("Predicted impressions for 5 ad slots is", predicted_imp, "\n")
```
### Predict 1 million impressions

Let's predict how many clicks could the manager generate on average if a website owner would sell 1M impressions on their website
```{r}
predicted_clicks <- predict(mod1, newdata = list(impressions=1000000))
cat("Predicted clicks for 1 million of impressions is", predicted_clicks, "\n")
```

# Task 3

### Multiple Regression

We run the multiple linear regression to investigate the effect the number of ads on the webpage and the number of impressions have on the amount of clicks received.
```{r}
lm_click_adnum_impr<- lm(clicks ~ number_ads + impressions, data = site_data)
click_lm_summary <- summary(lm_click_adnum_impr)
click_lm_summary
```
We can see that whicle the number of ads don't explain the number of clicks in a statistically significant way, the number of impressions do. Additionally, the adjusted R-squared is 45%, says that approximately 45% of the variability in the number of clicks can be explained by the number of ads and number of impressions combined.

Let's compare the results with d).
```{r}
cat("adj. r-squared for clicks ~ impressions:", d$adj.r.squared, "\n")
cat("adj. r-squared for clicks ~ number_ads:", e$adj.r.squared, "\n")
cat("adj. r-squared for clicks ~ number_ads + impressions:", click_lm_summary$adj.r.squared, "\n")
cat("coefficients for clicks ~ impressions:\n")
d$coefficients
cat("coefficients for clicks ~ number_ads:\n")
e$coefficients
cat("coefficients for clicks ~ number_ads + impressions:\n")
click_lm_summary$coefficients
```
According to adjusted r squared, our model has not improved. This suggests that the number of ads does not explain additional variability in clicks beyond what impressions already explains. In the multiple regression model, number_ads has an estimate of 0.62, although the P value is not statistically significant (p-value ~0.32) while impressions, although lower estimate, is statistically significant (p-value <0.001), which further confirmes this observation.

This could indicate that number_ads and impressions are correlated. Let's test this
```{r}
cor(site_data$number_ads, site_data$impressions)
```
We have a correlation of almost 70%, which is relatively high and might be behind why the inclusion of number_ads did not significantly improve our model.

We would recommend the manager to focus on increasing the amount of impressions on the webpage instead of focusing on the amount of ads displayed in order to achieve a more clicks. Increasing impressions has a strong statistical evidence to increase user engagement based on our analysis.

Additionally, since only around 45% of the variability in clicks is explained by the lm model, we would recommend the manage to conduct more tests, potentially incorporating other predictors. As an examples, incorporating view_rate, ctr, and quality variables in the lm model results in an adjusted r squared of ~80%
```{r}
summary(lm(clicks ~ number_ads + impressions + view_rate + ctr + quality, data = site_data))$adj.r.squared
```
Below see a visualization of the model.

## Plot

```{r}
ggplot(site_data, aes(x = number_ads, y = clicks, color = impressions)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", color = "black") +
  scale_color_gradient(low = "blue", high = "red") +
  labs(
    title = "Effects of ad number and impressions on clicks",
    x = "number of ads",
    y = "clicks",
    color = "Impressions"
  ) +
  theme_minimal()

```
